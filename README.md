# Comment Toxicity Detector

The Comment Toxicity Detector is a small deep learning project designed to automatically indentify and classify toxic comments. The primary goal of this project is to promote healthier online interactions by filtering out toxic comments.

Dataset Link: https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge

Input: String

Output: {
  "toxic": False,
  "severe_toxic": False,
  "obscene": False,
  "threat": False,
  "insult": False,
  "identity_hate": False
}

Screenshots:
![image](https://github.com/hbhavsar1002/comment_toxicity_detector/assets/30213124/5b4cce1e-da51-48d8-bbe9-60fe54df0b7c)
![image](https://github.com/hbhavsar1002/comment_toxicity_detector/assets/30213124/8e688f93-d7dc-4b92-a0da-32c85ded2034)
